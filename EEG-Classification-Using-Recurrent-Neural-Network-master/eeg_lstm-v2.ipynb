{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Classification from EEG\n",
    "#### Tyrome Sweet and Taran Rallings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following analyes EEG data taken in experiments where participants where exposed to light and sound events. This code cleans that 32 channel EEG data and uses a long short-term memory recurrent neural network to classify the time following light or sound events by which event occured. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting the random seed for reproducibility\n",
    "import random\n",
    "seed=42\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# eeg1 and events1 are the test data from a single person\n",
    "# code assumes eeg1 and events1 are csv files in the current working directory\n",
    "\n",
    "eeg1 = pd.read_csv(\"eeg1.csv\", delimiter=\"\\t\")\n",
    "new_columns = eeg1.columns.values \n",
    "new_columns[0] = 'time'     \n",
    "new_columns[33] = 'sample' \n",
    "eeg1.columns = new_columns\n",
    "\n",
    "events1 = pd.read_csv(\"events1.csv\") #, delimiter=\"\\t\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subsample of the data to ease building the model, unused in final run\n",
    "eeg1_smol = eeg1[0:785000]\n",
    "events1_smol = events1[0:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Toy data generator, unused in final run\n",
    "\n",
    "def generate_eeg(samples, time_steps, n_features, event_types):\n",
    "    # samples is Int number of trials \n",
    "    # time_steps is Int length of each trial in ms\n",
    "    # n_features is Int number of EEG channels\n",
    "    # event_types is Int number of stimula like lights and flashes\n",
    "    signals = generate_signals(samples, time_steps, n_features)\n",
    "    events = generate_events(event_types, samples)\n",
    "    events_1hot = one_hot_events(events)\n",
    "    return signals, events_1hot\n",
    "\n",
    "# helper function (generate_eeg) for making EEG signal data\n",
    "def generate_signals(samples, time_steps, n_features):\n",
    "    # data types same as main function\n",
    "    signals = np.random.random((samples, time_steps, n_features))\n",
    "    return signals\n",
    "\n",
    "# helper function (generate_eeg) for making one sample per event an\n",
    "def generate_events(event_types, samples):\n",
    "    # data types same as main function\n",
    "    events = np.random.randint(1, event_types, samples)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes in eeg dataframe and event dataframe, cleans them, 1hot encodes the events\n",
    "def clean_eeg(eeg, events, event_interval_length, eeg_slice_length):\n",
    "    #event_list = []\n",
    "    array_list = [] \n",
    "    index_list = []\n",
    "    eeg = standardize_eeg(eeg) # function for standardizing the eeg readings\n",
    "    #events_new = build_zero_events(events)\n",
    "    # iterate over the rows of the events and slice out the corresponding eeg data\n",
    "    for index, row in itertools.islice(events.iterrows(), event_interval_length): # loop through events data\n",
    "        #build_event_list(row, event_list) #\n",
    "        tmin, tmax = build_event_intervals(row, events)\n",
    "        eeg_slice = cut_event_intervals(eeg, tmin, tmax)\n",
    "        array_list, index_list = build_array(eeg_slice, eeg_slice_length, \n",
    "                                             index, index_list, array_list)\n",
    "    y_int = events.iloc[index_list] # take the event types for the correct index\n",
    "    y_int = y_int['type'].values    # take just the event types as an array\n",
    "    #y_int = y_int.as_matrix()            # save the event types as a matrix\n",
    "    #y, lb = one_hot_events(y_int)        # one-hot the event types and save the binarizer\n",
    "    X = np.stack(array_list, axis = 0)   # stack the arrays so the whole thing is 3D\n",
    "    return X, y_int                     # return the data, outputs, and the binarizer\n",
    "    \n",
    "        \n",
    "def build_event_list(row, event_list):\n",
    "    # helper function to pull event types out of event data in the right order\n",
    "    event_type = getattr(row, \"type\")\n",
    "    event_list.append(event_type)\n",
    "        \n",
    "def build_event_intervals(row, events):\n",
    "    # helper function to get the time intervals associated with each event\n",
    "    tmin = getattr(row, \"latency\")\n",
    "    tmin_in = getattr(row, \"number\")\n",
    "    tmax_in = tmin_in + 1\n",
    "    tmax = events1.loc[tmax_in, \"latency\"]\n",
    "    return tmin, tmax\n",
    "\n",
    "def cut_event_intervals(eeg, tmin, tmax):\n",
    "    # helper function to slice up the eeg data so each slice is associated with one event\n",
    "    eeg_slice = eeg.loc[(eeg[\"time\"] > tmin) & (eeg[\"time\"] < tmax)]\n",
    "    eeg_slice.drop([\"time\", \"sample\"], axis = 1, inplace = True)\n",
    "    return eeg_slice\n",
    "    \n",
    "def build_array(eeg_slice, eeg_slice_length, index, index_list, array_list):\n",
    "    # helper function to build an array out of the eeg slices and pad them out to a standard length\n",
    "    if len(eeg_slice) < eeg_slice_length:\n",
    "        index_list.append(index)\n",
    "        eeg_matrix = eeg_slice.as_matrix()\n",
    "        padded_matrix = np.pad(eeg_matrix, ((0, eeg_slice_length - len(eeg_matrix)), (0,0)),\n",
    "                                   'constant', constant_values=0)\n",
    "        array_list.append(padded_matrix)\n",
    "    return array_list, index_list\n",
    "\n",
    "def one_hot_events(events):\n",
    "    # helper function for one-hot encoding the events\n",
    "    events_list = list(events)\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(events_list)\n",
    "    events_1hot = lb.transform(events_list)\n",
    "    return events_1hot, lb\n",
    "\n",
    "def invert_one_hot(events, lb):\n",
    "    # function for decoding one-hot, binarizer made in one_hot_events\n",
    "    inv_events = lb.inverse_transform(events)\n",
    "    return inv_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize_eeg(eeg_data):\n",
    "    # breaks apart an eeg dataframe, scales the eeg readings, and reassmbles it into a dataframe\n",
    "    column_list = eeg_data.columns[1:33]\n",
    "    time = eeg_data['time']\n",
    "    sample = eeg_data['sample']\n",
    "    eeg_array = eeg_data[column_list]\n",
    "    eeg_stnd = scale_data(eeg_array)\n",
    "    eeg_stnd_df = pd.DataFrame(eeg_stnd, index=eeg_data.index, columns=column_list)\n",
    "    eeg_stnd = pd.concat([time, eeg_stnd_df, sample], axis =1)\n",
    "    return eeg_stnd\n",
    "\n",
    "def scale_data(unscaled_data):\n",
    "    # helper function for standardize_eeg, fits a scaler and transforms the data \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(unscaled_data)\n",
    "    scaled_data = scaler.transform(unscaled_data)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is unused code for breaking up the \"nothing happened\" periods of the eeg data \n",
    "# to associate with \"type 0\" events. \n",
    "\n",
    "import math\n",
    "time_steps = 1300\n",
    "\n",
    "def build_zero_events(event_data, time_steps=time_steps):\n",
    "    new_events = build_new_events(event_data, time_steps)\n",
    "    events = zero_events(event_data, new_events)\n",
    "    return events\n",
    "\n",
    "\n",
    "def build_new_events(event_data, time_steps= time_steps):\n",
    "    first_event_time = event_data['latency'].loc[1]\n",
    "    number_new_intervals = math.floor(first_event_time / time_steps)\n",
    "    df = pd.DataFrame(columns=['number', 'latency', 'type', 'duration'],index = range(number_new_intervals) )\n",
    "    latency = 0\n",
    "    for t in range(number_new_intervals):\n",
    "        latency += 1300\n",
    "        df.loc[t].latency = latency\n",
    "        df.loc[t].type = 0\n",
    "    return df\n",
    "\n",
    "def zero_events(event_data, new_events):\n",
    "    events_zeros = event_data[event_data.latency != 1]\n",
    "    events_zeros= new_events.append(events_zeros)\n",
    "    events_zeros = events_zeros.reset_index(drop=True)\n",
    "    events_zeros['number'] = events_zeros.index + 1\n",
    "    return events_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# full dataset parameters\n",
    "\n",
    "# define model parameters\n",
    "samples = 3625  # how many trials of eeg data\n",
    "n_features = 32  # how many channels of eeg in each sample\n",
    "time_steps = 1300 # how many ms was each sample run for\n",
    "event_types = 2 #len(set(y))  # how many different event types (light, sound, etc) are there # 6 large, 4 smol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tyrom\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# get the data into useable form and store as X and y\n",
    "X, y = clean_eeg(eeg1, events1, samples, time_steps)  #4250 long, 998 short, 4330 long enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removes the minor event types. There were only a couple hundred examples of each, whereas the used events had a \n",
    "# couple thousand examples\n",
    "remove_list = [0,2,4,5,6]              # designate unwanted event types\n",
    "drop_list = np.isin(y, remove_list)    # create a list of indices associated with unwanted events                  \n",
    "drop_array = np.array(drop_list)       # make the list of indices to drop into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make X, y's with the unwanted events removed\n",
    "y_short_int = y[np.isin(y,remove_list, invert=True)]\n",
    "X_short = X[np.isin(y, remove_list, invert=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode the y data without the unwanted events\n",
    "y_short, lb = one_hot_events(y_short_int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# use strat. shuffle split to get indices for test and training data \n",
    "sss = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state=seed)\n",
    "sss.get_n_splits(X_short, y_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take the indices generated by stratified shuffle split and make the test and training datasets\n",
    "for train_index, test_index in sss.split(X_short, y_short):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_short[train_index], X_short[test_index]\n",
    "    y_train, y_test = y_short[train_index], y_short[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2444/2444 [==============================] - 91s 37ms/step - loss: 0.6797 - acc: 0.5966\n",
      "Epoch 2/50\n",
      "2444/2444 [==============================] - 89s 37ms/step - loss: 0.6744 - acc: 0.5978\n",
      "Epoch 3/50\n",
      "2444/2444 [==============================] - 89s 36ms/step - loss: 0.6774 - acc: 0.5949\n",
      "Epoch 4/50\n",
      "2444/2444 [==============================] - 90s 37ms/step - loss: 0.6755 - acc: 0.5974\n",
      "Epoch 5/50\n",
      "2444/2444 [==============================] - 89s 37ms/step - loss: 0.6746 - acc: 0.5941\n",
      "Epoch 6/50\n",
      "2444/2444 [==============================] - 90s 37ms/step - loss: 0.6726 - acc: 0.5974\n",
      "Epoch 7/50\n",
      "2444/2444 [==============================] - 89s 37ms/step - loss: 0.6728 - acc: 0.5962\n",
      "Epoch 8/50\n",
      "2444/2444 [==============================] - 90s 37ms/step - loss: 0.6746 - acc: 0.5990\n",
      "Epoch 9/50\n",
      "2444/2444 [==============================] - 90s 37ms/step - loss: 0.6641 - acc: 0.5998\n",
      "Epoch 10/50\n",
      "2444/2444 [==============================] - 90s 37ms/step - loss: 0.6565 - acc: 0.6117\n",
      "Epoch 11/50\n",
      "2444/2444 [==============================] - 92s 38ms/step - loss: 0.6482 - acc: 0.6244\n",
      "Epoch 12/50\n",
      "2444/2444 [==============================] - 91s 37ms/step - loss: 0.6362 - acc: 0.6588\n",
      "Epoch 13/50\n",
      "2444/2444 [==============================] - 103s 42ms/step - loss: 0.6170 - acc: 0.6772\n",
      "Epoch 14/50\n",
      "2444/2444 [==============================] - 120s 49ms/step - loss: 0.6057 - acc: 0.6952\n",
      "Epoch 15/50\n",
      "2444/2444 [==============================] - 107s 44ms/step - loss: 0.5828 - acc: 0.7193\n",
      "Epoch 16/50\n",
      "2444/2444 [==============================] - 104s 43ms/step - loss: 0.5613 - acc: 0.7345\n",
      "Epoch 17/50\n",
      "2444/2444 [==============================] - 92s 38ms/step - loss: 0.5466 - acc: 0.7541\n",
      "Epoch 18/50\n",
      "2444/2444 [==============================] - 90s 37ms/step - loss: 0.5585 - acc: 0.7369\n",
      "Epoch 19/50\n",
      "2444/2444 [==============================] - 91s 37ms/step - loss: 0.5161 - acc: 0.7762\n",
      "Epoch 20/50\n",
      "2444/2444 [==============================] - 90s 37ms/step - loss: 0.5025 - acc: 0.7815\n",
      "Epoch 21/50\n",
      "2444/2444 [==============================] - 89s 37ms/step - loss: 0.5028 - acc: 0.7844\n",
      "Epoch 22/50\n",
      "2444/2444 [==============================] - 92s 38ms/step - loss: 0.4593 - acc: 0.8081\n",
      "Epoch 23/50\n",
      "2444/2444 [==============================] - 93s 38ms/step - loss: 0.4517 - acc: 0.8159\n",
      "Epoch 24/50\n",
      "2444/2444 [==============================] - 91s 37ms/step - loss: 0.4370 - acc: 0.8355\n",
      "Epoch 25/50\n",
      "2444/2444 [==============================] - 92s 38ms/step - loss: 0.4267 - acc: 0.8245\n",
      "Epoch 26/50\n",
      "2444/2444 [==============================] - 90s 37ms/step - loss: 0.4536 - acc: 0.8142\n",
      "Epoch 27/50\n",
      "2444/2444 [==============================] - 89s 36ms/step - loss: 0.3935 - acc: 0.8474\n",
      "Epoch 28/50\n",
      "2444/2444 [==============================] - 89s 37ms/step - loss: 0.3910 - acc: 0.8531\n",
      "Epoch 29/50\n",
      "2444/2444 [==============================] - 89s 37ms/step - loss: 0.3441 - acc: 0.8711\n",
      "Epoch 30/50\n",
      "2444/2444 [==============================] - 92s 38ms/step - loss: 0.3409 - acc: 0.8793\n",
      "Epoch 31/50\n",
      "2444/2444 [==============================] - 93s 38ms/step - loss: 0.3353 - acc: 0.8818\n",
      "Epoch 32/50\n",
      "2444/2444 [==============================] - 91s 37ms/step - loss: 0.3258 - acc: 0.8912\n",
      "Epoch 33/50\n",
      "2444/2444 [==============================] - 91s 37ms/step - loss: 0.3134 - acc: 0.8895\n",
      "Epoch 34/50\n",
      "2444/2444 [==============================] - 91s 37ms/step - loss: 0.3098 - acc: 0.8944\n",
      "Epoch 35/50\n",
      "2444/2444 [==============================] - 89s 37ms/step - loss: 0.2832 - acc: 0.9063\n",
      "Epoch 36/50\n",
      "2444/2444 [==============================] - 90s 37ms/step - loss: 0.2607 - acc: 0.9108\n",
      "Epoch 37/50\n",
      "2444/2444 [==============================] - 92s 38ms/step - loss: 0.2477 - acc: 0.9210\n",
      "Epoch 38/50\n",
      "2444/2444 [==============================] - 91s 37ms/step - loss: 0.2257 - acc: 0.9259\n",
      "Epoch 39/50\n",
      "2444/2444 [==============================] - 92s 38ms/step - loss: 0.2193 - acc: 0.9284\n",
      "Epoch 40/50\n",
      "2444/2444 [==============================] - 92s 38ms/step - loss: 0.2474 - acc: 0.9194\n",
      "Epoch 41/50\n",
      "2444/2444 [==============================] - 91s 37ms/step - loss: 0.1983 - acc: 0.9345\n",
      "Epoch 42/50\n",
      "2444/2444 [==============================] - 91s 37ms/step - loss: 0.2084 - acc: 0.9390\n",
      "Epoch 43/50\n",
      "2444/2444 [==============================] - 93s 38ms/step - loss: 0.2007 - acc: 0.9296\n",
      "Epoch 44/50\n",
      "2444/2444 [==============================] - 91s 37ms/step - loss: 0.2197 - acc: 0.9341\n",
      "Epoch 45/50\n",
      "2444/2444 [==============================] - 93s 38ms/step - loss: 0.1765 - acc: 0.9489\n",
      "Epoch 46/50\n",
      "2444/2444 [==============================] - 92s 37ms/step - loss: 0.1899 - acc: 0.9419\n",
      "Epoch 47/50\n",
      "2444/2444 [==============================] - 90s 37ms/step - loss: 0.1719 - acc: 0.9489\n",
      "Epoch 48/50\n",
      "2444/2444 [==============================] - 89s 37ms/step - loss: 0.1890 - acc: 0.9407\n",
      "Epoch 49/50\n",
      "2444/2444 [==============================] - 91s 37ms/step - loss: 0.1537 - acc: 0.9542\n",
      "Epoch 50/50\n",
      "2444/2444 [==============================] - 91s 37ms/step - loss: 0.1692 - acc: 0.9538\n",
      "612/612 [==============================] - 4s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "\n",
    "# code for building an LSTM with 100 neurons and dropout. Runs for 50 epochs\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=False, input_shape=(time_steps, n_features)))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(LSTM(100)) dramatically worse results\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=16, epochs=50)\n",
    "score = model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.65204278495333168, 0.80882352941176472]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.88%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.2f%%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saved model details\n",
    "standardized\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(2, output_dim=256))\n",
    "model.add(LSTM(100, input_shape=(time_steps, n_features)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=16, epochs=50)\n",
    "score = model.evaluate(X_test, y_test, batch_size=16)\n",
    "\n",
    "This model run for 50 epochs had:\n",
    "\n",
    "* binary crossentropy 0.41922928811677918\n",
    "\n",
    "* accuracy 0.8529411764705882"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
